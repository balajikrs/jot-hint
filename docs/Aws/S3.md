# Simple Storage Service (S3)

- Object storage
- Global storage platform - regional based/resilient (data is stored in a specific aws region at rest)
  :::tip Imp
  Public service - runs in Aws public zone - unlimited - multiuser -
  can tolerate a failure of a AZ and has few replication abilities
  :::
- Economical and accessed by
  - HTTP
  - API
  - GUI
  - CLI
- Delivers Objects and buckets

# Objects and buckets

- object has a key - that Obj can be referenced using a key in a bucket
- by default none has access to a public bucket except the root user
- Value - content being stored / binary data of the images or videos
- object can be between 0 byte and 5 terabytes
- object has
  - version id
  - metadata
  - Access control
  - subresouces
- Buckets
  - created in specific aws region - data never leaves a region unless we do so
  - name should be globally unique
  - S3 has stable data sovereignty
  - Blast radius is a region
  - Buckets can have unlimited number of objects
  - Flat structure - all objects are stored at same level
  - 3 - 63 characters - all lowercase no underscores
  - starts with lowercase or number
  - cannot be formated as ip address like 1.1.1.1
  - soft limit 100 buckets for an account ; 1000 is hard limit per account
  - key is the name value is the data
  - folder like stuctures are just prefixes
  - cannot mount in linux or windows as they are not file or block storage
  - 1 EBS can be attached to one instance but s3 we can do multi access
  - great for offload in things
  - great for large scale data storage, distribution or upload
  - default for any input or output aws products

# S3 Encryption

- Client-Side Encryption
- SSE-C
- SSE-S3
- SSE-KMS
  - SSE-KMS impacts permissions and how it can achieve role separation.
- SSE-S3
- AES-256

# S3 Storage classes
## S3 Standard `should be accessed for frequently accessed data and non replaceable `
  - objects are replicated across minimum 3 AZ
  - 11 9's durablity means  for 10,000,000 objects 1 objects loss per 10000 years
  - Replication does MD5 checksums, Cyclic redundancy checks are used to detect and fix any data corruption
  - `when stored successfully/durably - s3 retuns http 1.1 200 ok status `
  - Billing
    - GB per month fee for data stored
    - $ per GB of data transfered `out`
    - IN is free
    - price per 1000 requests
    - No specific retrival fee
    - No Minumum duration
    - no Minimum size
  - Milli-second first byte latency
    - objects can be publicly available
## S3 Standard - IA ( Infrequent access - for Long lived data and where data access is infrequent and for tiny objects)
  - Cost effective compared to standard 
  - Comprise 
    - New cost component - `retrival fee` (per GB)
    - minimum usage charge of 30 days (even though you stored the data for 4 days it will be charged for 30 days)
    - even less data stored each obj is charge equivalent of 128 kb for per object
## S3 Standard - one zone - IA ( Infrequent access - )
  - Comprise 
    - New cost component - `retrival fee` (per GB)
    - minimum usage charge of 30 days (even though you stored the data for 4 days it will be charged for 30 days)
    - even less data stored each obj is charge equivalent of 128 kb for per object
    - stored in only one zone (no replication across multiple AZ)
  - Use for 
    - Long lived data 
    - non-critical / replaceable 
    - infrequent
    - Can be used for replica copies 
    - can be used for intermediate data we can loose
  - `Dont` use for
    - Only copy of data
    - critcal data
    - frequently accessed
    - temporary data or tiny data
# S3 Glacier - Instant access
  - data in chilled state
  - minimum duration 90 days of charge
  - Instant access
  - 
# S3 - Glacier - Flexible
  - data in cold state
  - 1/6 of the cost of s3-standard
  - Trade offs
    - They are for cold objects(they are not for warm or ready for use)
    - not immediately available
    - cannot be made public
    - Can see in s3 bucket but they are pointer to the object
    - retrival process / payment for retrival fee
    - when retriving they will be stored in a S3-IA bucket temporaryly and after accessing it will be removed
    - Retrival 3 options
      - expediated - 1-5 minutes
      - standard - 3-5 hours
      - bulk - 4-12 hours
      - Faster the retrival more the cost
    - First byte latency is minutes or hours
    - 40 kb minimum billable cost
    - 90 days minimum duration\
  - Used for 
    - archival data
    - frequent or real-time access is not needed
      - e.g. yearly access data
# S3 - Glacier Deep archive (`cheaper one`)
  - data in frozen state
  - Trade offs
    - 180 day minimum billable
    - 40 kb minimum billable size
    - no public access
    - retrival job needed
    - Retrival opions
      - standard - 12 hours
      - bulk - 48 hours
      - First byte retrival - hours/days
  - used for
    - Archival and rarely accesed
    - secondary long time retrival backups
    - legal and regulatory requiremnents
  - Dont use for
    - Backups (due to long retrival time)
# S3 - Inteligent Tiering
  - contains 5 different storage tiers
    - Frequent Access (like s3 std) 
    - Infrequent Access (s3 IA) 
    - Archive instant access (90 days)
    - Archive Access(90 - 270 days)
    - Deep Archive(180 - 730 days)
  - Monitoring cost - -per 1000 objects
  - Used for 
    - long lived data
    - changing or unknown patterns
# S3 Lifecycle configuration
  - to optimise cost over time
 - set of rules to s3 bucket
 - rules - can apply to whole bucket or groups(defined by prefix or type) of object in that bucket
  - Transition Actions
    - s3 std to IA after 30 days (eg )
  - Expiration actions
    - delete whatever object /object versions
  - Can't move objects based on acces frequency (only Inteligent tiering does this)
